{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefb1f19",
   "metadata": {},
   "source": [
    "# A3 â€“ AlexNET-VGG: CNN Variants (CPU-Only)Â¶\n",
    "## CIFAR-10 | AlexNet-like vs VGG-style (from scratch)\n",
    "### Starter Notebook\n",
    "\n",
    "**Hardware assumption:** CPU-only laptops/PC for training\n",
    "**Dataset:** CIFAR-10 (32Ã—32 RGB, 10 classes)  \n",
    "**Recommended settings:** `IMG_SIZE=(32,32)`, `BATCH_SIZE=64`, `EPOCHS=10â€“15`\n",
    "\n",
    "**Learning goals**\n",
    "- Implement two landmark CNN *styles* from scratch (AlexNet-like vs VGG-style)\n",
    "- Compare **depth vs width**, **downsampling strategy**, **params vs accuracy**, and **training time**\n",
    "- Perform a small **regularization mini-experiment** and **error analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bbdd5",
   "metadata": {},
   "source": [
    "## Q0 â€” Setup (Ungraded)\n",
    "Import libraries, set seeds, and check TensorFlow availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices(\"GPU\"))  # OK if empty on CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25ba6b-63f1-4f10-ad40-e50c5a9b8dbe",
   "metadata": {},
   "source": [
    "## âœ… Student Instructions (Start Here)\n",
    "\n",
    "Your work begins in the **next code cells (Q1â€“Q8)** and continues by answering questions in the **Markdown cells (Q9â€“Q11)**. These correspond to the questions listed in the assignment description on Canvas. Complete each cell by following the instructions provided in the **preceding Markdown cells**.\n",
    "\n",
    "Please:\n",
    "- **Read the instructions carefully** before you begin coding.\n",
    "- Take time to **understand each question** and implement the required steps.\n",
    "- Each code cell includes **partial starter code**â€”your task is to **fill in the missing parts** and ensure the cell runs correctly.\n",
    "\n",
    "If you need clarification at any point, please contact the **teaching staff (instructor/TA)** for support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397c5d9",
   "metadata": {},
   "source": [
    "## Q1 â€” Load CIFAR-10 & Inspect (Warm-up)\n",
    "\n",
    "Load CIFAR-10 using `tf.keras.datasets.cifar10.load_data()`.\n",
    "\n",
    "Print:\n",
    "- shapes of train/test\n",
    "- number of classes\n",
    "- show 12 sample images with labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q1 â€” Load and Visualize CIFAR-10 (Fill in the Blanks)\n",
    "# ============================================================\n",
    "# Complete the TODO sections to:\n",
    "#  1) Load CIFAR-10 using tf.keras.datasets\n",
    "#  2) Fix label shapes (squeeze)\n",
    "#  3) Define class names and number of classes\n",
    "#  4) Print dataset shapes\n",
    "#  5) Visualize 12 training images with correct class labels\n",
    "# ============================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO 1: Load CIFAR-10 data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.__________.load_data()\n",
    "\n",
    "# TODO 2: Convert labels from shape (N,1) -> (N,) using squeeze()\n",
    "y_train = y_train.__________()\n",
    "y_test  = y_test.__________()\n",
    "\n",
    "# TODO 3: Define the CIFAR-10 class names (10 categories)\n",
    "class_names = [\n",
    "    \"__________\", \"__________\", \"__________\", \"__________\", \"__________\",\n",
    "    \"__________\", \"__________\", \"__________\", \"__________\", \"__________\"\n",
    "]\n",
    "\n",
    "# TODO 4: Set number of classes\n",
    "num_classes = ______\n",
    "\n",
    "# TODO 5: Print shapes of train/test splits\n",
    "print(\"x_train:\", x_train.__________, \"y_train:\", y_train.__________)\n",
    "print(\"x_test :\", x_test.__________,  \"y_test :\", y_test.__________)\n",
    "print(\"Num classes:\", num_classes)\n",
    "\n",
    "# TODO 6: Plot a grid of 12 images (3 rows Ã— 4 columns)\n",
    "plt.figure(figsize=(____, ____))\n",
    "for i in range(____):\n",
    "    ax = plt.subplot(____, ____, i + 1)\n",
    "\n",
    "    # TODO 7: Show the image\n",
    "    plt.__________(x_train[i])\n",
    "\n",
    "    # TODO 8: Set the title using the correct class name\n",
    "    plt.title(class_names[int(________________)], fontsize=____)\n",
    "\n",
    "    # TODO 9: Hide axes\n",
    "    plt.axis(\"____\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594d4f3",
   "metadata": {},
   "source": [
    "## Q2 â€” Preprocessing & `tf.data` Pipeline (CPU-friendly)\n",
    "\n",
    "Build pipelines that:\n",
    "- Convert to `float32` and scale to **[0,1]**\n",
    "- Apply light augmentation to training only (flip + small brightness/contrast)\n",
    "- Use `shuffle` (train), `batch`, `prefetch`\n",
    "\n",
    "Then print one batch shape and value range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaaf9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q2 â€” tf.data Preprocessing & Augmentation (Fill in the Blanks)\n",
    "# ============================================================\n",
    "# Complete the TODO sections to:\n",
    "#  1) Define dataset constants\n",
    "#  2) Normalize image pixels\n",
    "#  3) Apply data augmentation\n",
    "#  4) Build train, validation, and test tf.data pipelines\n",
    "#  5) Inspect a batch of images\n",
    "# ============================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# TODO 1: Define image size (height, width)\n",
    "IMG_SIZE = (____, ____)\n",
    "\n",
    "# TODO 2: Define batch size\n",
    "BATCH_SIZE = ____\n",
    "\n",
    "# TODO 3: Enable tf.data autotuning\n",
    "AUTOTUNE = tf.data.__________\n",
    "\n",
    "# -------- Preprocessing --------\n",
    "def preprocess(image, label):\n",
    "    # TODO 4: Cast image to float32 and normalize to [0, 1]\n",
    "    image = tf.__________(image, tf.__________) / ______\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# -------- Data Augmentation --------\n",
    "def augment(image, label):\n",
    "    # TODO 5: Random horizontal flip with a fixed seed\n",
    "    image = tf.image.________________________(image, seed=____)\n",
    "\n",
    "    # TODO 6: Random brightness adjustment\n",
    "    image = tf.image.________________________(image, max_delta=____)\n",
    "\n",
    "    # TODO 7: Random contrast adjustment\n",
    "    image = tf.image.________________________(\n",
    "        image, lower=____, upper=____\n",
    "    )\n",
    "    return image, label\n",
    "\n",
    "\n",
    "# -------- Training Dataset --------\n",
    "# TODO 8: Create tf.data Dataset from training arrays\n",
    "train_ds = tf.data.Dataset.________________________((x_train, y_train))\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    # TODO 9: Apply preprocessing in parallel\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    # TODO 10: Apply data augmentation\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    # TODO 11: Shuffle the dataset\n",
    "    .shuffle(______, seed=____)\n",
    "    # TODO 12: Batch the dataset\n",
    "    .batch(______)\n",
    "    # TODO 13: Prefetch for performance\n",
    "    .prefetch(__________)\n",
    ")\n",
    "\n",
    "# -------- Validation Dataset --------\n",
    "# TODO 14: Number of samples used for validation\n",
    "val_split = ____\n",
    "\n",
    "val_ds = tf.data.Dataset.________________________(\n",
    "    (x_train[-________:], y_train[-________:])\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    val_ds\n",
    "    # TODO 15: Apply preprocessing only (no augmentation)\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    .batch(______)\n",
    "    .prefetch(__________)\n",
    ")\n",
    "\n",
    "# -------- Updated Training Dataset (Exclude Validation Samples) --------\n",
    "train_ds = tf.data.Dataset.________________________(\n",
    "    (x_train[:-________], y_train[:-________])\n",
    ")\n",
    "\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    .shuffle(______, seed=____)\n",
    "    .batch(______)\n",
    "    .prefetch(__________)\n",
    ")\n",
    "\n",
    "# -------- Test Dataset --------\n",
    "test_ds = tf.data.Dataset.________________________((x_test, y_test))\n",
    "\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    # TODO 16: Apply preprocessing only\n",
    "    .map(__________________, num_parallel_calls=__________)\n",
    "    .batch(______)\n",
    "    .prefetch(__________)\n",
    ")\n",
    "\n",
    "# -------- Inspect & print One Batch Info--------\n",
    "images, labels = next(iter(train_ds))\n",
    "print(\"Batch images:\", images.shape, \"Batch labels:\", labels.shape)\n",
    "print(\"Pixel range:\", float(tf.reduce_min(images)), \"to\", float(tf.reduce_max(images)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa7a76",
   "metadata": {},
   "source": [
    "## Q3 â€” Implement AlexNet-like CNN (CIFAR-10)\n",
    "\n",
    "CIFAR-10 images are 32Ã—32, so AlexNet must be **adapted**:\n",
    "- Use a larger kernel early (e.g., 5Ã—5) but avoid stride 4\n",
    "- Use MaxPooling\n",
    "- Use Dropout in head\n",
    "- Output softmax over 10 classes\n",
    "\n",
    "Deliverables: `summary()` + param count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q3 â€” Build AlexNet-Style CNN for CIFAR-10 (Fill in the Blanks)\n",
    "# ============================================================\n",
    "# Complete the TODO sections to correctly build, compile,\n",
    "# and summarize an AlexNet-inspired CNN for CIFAR-10.\n",
    "#\n",
    "# Keep the overall architecture the same.\n",
    "# ============================================================\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_alexnet_cifar(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # TODO 1: Define the input layer\n",
    "    inputs = layers.__________(shape=__________________)\n",
    "\n",
    "    # -------- Block 1 --------\n",
    "    # TODO 2: Conv2D with 64 filters, kernel size 5, same padding, ReLU\n",
    "    x = layers.__________(_____, _____, padding=\"_____\", activation=\"_____\")(inputs)\n",
    "\n",
    "    # TODO 3: Batch Normalization\n",
    "    x = layers.________________()(x)\n",
    "\n",
    "    # TODO 4: MaxPooling with pool size 2 (32 -> 16)\n",
    "    x = layers.__________________(_____)(x)\n",
    "\n",
    "    # -------- Block 2 --------\n",
    "    # TODO 5: Conv2D with 128 filters, kernel size 3, same padding, ReLU\n",
    "    x = layers.__________(_____, _____, padding=\"_____\", activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 6: Batch Normalization\n",
    "    x = layers.________________()(x)\n",
    "\n",
    "    # TODO 7: MaxPooling with pool size 2 (16 -> 8)\n",
    "    x = layers.__________________(_____)(x)\n",
    "\n",
    "    # -------- Block 3 --------\n",
    "    # TODO 8: Conv2D with 192 filters, kernel size 3, same padding, ReLU\n",
    "    x = layers.__________(_____, _____, padding=\"_____\", activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 9: Another Conv2D with 192 filters, kernel size 3\n",
    "    x = layers.__________(_____, _____, padding=\"_____\", activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 10: MaxPooling with pool size 2 (8 -> 4)\n",
    "    x = layers.__________________(_____)(x)\n",
    "\n",
    "    # -------- Classifier --------\n",
    "    # TODO 11: Flatten layer\n",
    "    x = layers.__________()(x)\n",
    "\n",
    "    # TODO 12: Dense layer with 256 units and ReLU\n",
    "    x = layers.__________(_____, activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 13: Dropout with rate 0.5\n",
    "    x = layers.__________(_____)(x)\n",
    "\n",
    "    # TODO 14: Output layer with num_classes and softmax\n",
    "    outputs = layers.__________(_____, activation=\"_____\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"AlexNet_CIFAR\")\n",
    "\n",
    "\n",
    "# TODO 15: Build the model using IMG_SIZE and num_classes\n",
    "alex_model = build_alexnet_cifar(\n",
    "    input_shape=____________________,\n",
    "    num_classes=____________________\n",
    ")\n",
    "\n",
    "# TODO 16: Compile with Adam(3e-4), sparse categorical crossentropy, accuracy\n",
    "alex_model.compile(\n",
    "    optimizer=tf.keras.optimizers.__________(_____),\n",
    "    loss=\"_______________________________\",\n",
    "    metrics=[\"__________\"]\n",
    ")\n",
    "\n",
    "# TODO 17: Print the model summary\n",
    "alex_model.__________()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f2cc3",
   "metadata": {},
   "source": [
    "## Q4 â€” Implement VGG-style CNN (CIFAR-10)\n",
    "\n",
    "VGG-style (scaled for 32Ã—32):\n",
    "- Only 3Ã—3 conv\n",
    "- Blocks: (Convâ€“ReLU)Ã—2 â†’ MaxPool\n",
    "- Channels: 32 â†’ 64 â†’ 128 (optionally 256)\n",
    "- Use GlobalAveragePooling + Dense head + Dropout\n",
    "\n",
    "Deliverables: `summary()` + param count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649b74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q4 â€” VGG-Style CNN for CIFAR-10 (Fill in the Blanks)\n",
    "# ============================================================\n",
    "# Complete the TODO sections to build a VGG-style CNN using\n",
    "# reusable convolution blocks.\n",
    "#\n",
    "# Do NOT change the overall structure of the code.\n",
    "# ============================================================\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_block(x, filters, n_convs=2):\n",
    "    # TODO 1: Repeat convolution n_convs times\n",
    "    for _ in range(____________):\n",
    "        # TODO 2: Add a Conv2D layer with kernel size 3 and ReLU activation\n",
    "        x = layers.__________(filters, _____, padding=\"_____\", activation=\"_____\")(x)\n",
    "\n",
    "        # TODO 3: Add Batch Normalization\n",
    "        x = layers.________________()(x)\n",
    "\n",
    "    # TODO 4: Add MaxPooling with pool size 2\n",
    "    x = layers.__________________(_____)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_vgg_cifar(input_shape=(32, 32, 3), num_classes=10):\n",
    "    # TODO 5: Define the input layer\n",
    "    inputs = layers.__________(shape=__________________)\n",
    "\n",
    "    # -------- Feature Extraction --------\n",
    "    # TODO 6: First conv block (32 filters, 2 convolutions)\n",
    "    x = conv_block(inputs, _____, _____)   # 32 -> 16\n",
    "\n",
    "    # TODO 7: Second conv block (64 filters, 2 convolutions)\n",
    "    x = conv_block(x, _____, _____)        # 16 -> 8\n",
    "\n",
    "    # TODO 8: Third conv block (128 filters, 2 convolutions)\n",
    "    x = conv_block(x, _____, _____)        # 8 -> 4\n",
    "\n",
    "    # -------- Classification Head --------\n",
    "    # TODO 9: Apply Global Average Pooling\n",
    "    x = layers.________________________()(x)\n",
    "\n",
    "    # TODO 10: Dense layer with 128 units and ReLU activation\n",
    "    x = layers.Dense(_____, activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 11: Dropout with rate 0.4\n",
    "    x = layers.__________(_____)(x)\n",
    "\n",
    "    # TODO 12: Output layer with softmax activation\n",
    "    outputs = layers.Dense(_____, activation=\"_____\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs, outputs, name=\"VGG_CIFAR\")\n",
    "\n",
    "\n",
    "# TODO 13: Build the model using IMG_SIZE and num_classes\n",
    "vgg_model = build_vgg_cifar(\n",
    "    input_shape=____________________,\n",
    "    num_classes=____________________\n",
    ")\n",
    "\n",
    "# TODO 14: Compile the model using Adam optimizer (lr = 3e-4)\n",
    "vgg_model.compile(\n",
    "    optimizer=tf.keras.optimizers.__________(_____),\n",
    "    loss=\"_______________________________\",\n",
    "    metrics=[\"__________\"]\n",
    ")\n",
    "\n",
    "# TODO 15: Display the model summary\n",
    "vgg_model.__________()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712881a",
   "metadata": {},
   "source": [
    "## Q5 â€” Train Both Models (CPU-friendly)\n",
    "\n",
    "Train both for **10â€“15 epochs** with:\n",
    "- EarlyStopping(val_accuracy)\n",
    "- ReduceLROnPlateau(val_loss)\n",
    "\n",
    "Record:\n",
    "- training time\n",
    "- best validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aeb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q5 â€” Training, Callbacks, and Model Comparison\n",
    "# ============================================================\n",
    "# Complete the TODO sections to:\n",
    "#  1) Define training callbacks\n",
    "#  2) Train AlexNet- and VGG-style models\n",
    "#  3) Measure training time\n",
    "#  4) Compare best validation accuracy\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# -------- Callbacks --------\n",
    "def make_callbacks(prefix):\n",
    "    return [\n",
    "        # TODO 1: Stop training early if validation accuracy does not improve\n",
    "        tf.keras.callbacks.________________(\n",
    "            monitor=\"_______________\",\n",
    "            patience=____,\n",
    "            restore_best_weights=____\n",
    "        ),\n",
    "\n",
    "        # TODO 2: Reduce learning rate when validation loss plateaus\n",
    "        tf.keras.callbacks.________________(\n",
    "            monitor=\"_______________\",\n",
    "            factor=____,\n",
    "            patience=____,\n",
    "            min_lr=____\n",
    "        ),\n",
    "\n",
    "        # TODO 3: Save the best model based on validation accuracy\n",
    "        tf.keras.callbacks.________________(\n",
    "            filepath=f\"{__________}.keras\",\n",
    "            monitor=\"_______________\",\n",
    "            save_best_only=____\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "# TODO 4: Number of training epochs (15)\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "# -------- Train AlexNet-style Model --------\n",
    "# TODO 5: Record start time\n",
    "t0 = time.__________()\n",
    "\n",
    "# TODO 6: Train AlexNet model\n",
    "hist_alex = alex_model.__________(\n",
    "    train_ds,\n",
    "    validation_data=__________,\n",
    "    epochs=__________,\n",
    "    callbacks=____________________\n",
    ")\n",
    "\n",
    "# TODO 7: Compute training time\n",
    "time_alex = time.__________() - t0\n",
    "\n",
    "\n",
    "# -------- Train VGG-style Model --------\n",
    "t0 = time.__________()\n",
    "\n",
    "# TODO 8: Train VGG model\n",
    "hist_vgg = vgg_model.__________(\n",
    "    train_ds,\n",
    "    validation_data=__________,\n",
    "    epochs=__________,\n",
    "    callbacks=____________________\n",
    ")\n",
    "\n",
    "# TODO 9: Compute training time\n",
    "time_vgg = time.__________() - t0\n",
    "\n",
    "\n",
    "# -------- Performance Comparison --------\n",
    "# TODO 10: Best validation accuracy for AlexNet\n",
    "best_val_alex = float(\n",
    "    np.__________(hist_alex.history.get(\"_______________\", [np.nan]))\n",
    ")\n",
    "\n",
    "# TODO 11: Best validation accuracy for VGG\n",
    "best_val_vgg = float(\n",
    "    np.__________(hist_vgg.history.get(\"_______________\", [np.nan]))\n",
    ")\n",
    "\n",
    "# TODO 12: Print formatted comparison results\n",
    "print(f\"AlexNet-like: time={time_alex:.1f}s | best val acc={best_val_alex:.4f}\")\n",
    "print(f\"VGG-style  : time={time_vgg:.1f}s | best val acc={best_val_vgg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ca7c4c",
   "metadata": {},
   "source": [
    "## Q6 â€” Evaluate & Compare (Params, Time, Accuracy) + Curves\n",
    "\n",
    "Compute:\n",
    "- parameter count\n",
    "- test accuracy\n",
    "- training time\n",
    "\n",
    "Plot val_accuracy curves for both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7091f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q6 â€” Final Evaluation, Parameter Count, and Plotting\n",
    "# ============================================================\n",
    "# Complete the TODO sections to:\n",
    "#  1) Compute total trainable + non-trainable parameters from model.variables\n",
    "#  2) Evaluate both models on the test set\n",
    "#  3) Create a compact comparison summary\n",
    "#  4) Plot validation accuracy curves for both models\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def total_params(model):\n",
    "    # TODO 1: Compute total number of parameters in a model\n",
    "    # Hint: sum over np.prod(v.shape) for each variable v in model.variables\n",
    "    return int(np.sum([__________________________ for v in model.__________]))\n",
    "\n",
    "\n",
    "# -------- Test Evaluation --------\n",
    "# TODO 2: Evaluate AlexNet-like model on test_ds and extract accuracy (index 1)\n",
    "alex_test_acc = float(alex_model.__________(__________, verbose=0)[____])\n",
    "\n",
    "# TODO 3: Evaluate VGG-style model on test_ds and extract accuracy (index 1)\n",
    "vgg_test_acc  = float(vgg_model.__________(__________, verbose=0)[____])\n",
    "\n",
    "\n",
    "# -------- Build Summary Table --------\n",
    "# TODO 4: Build a list of tuples: (name, test_acc, time_sec, params)\n",
    "summary = [\n",
    "    (\"____________\", alex_test_acc, float(__________), total_params(__________)),\n",
    "    (\"____________\", vgg_test_acc,  float(__________), total_params(__________)),\n",
    "]\n",
    "\n",
    "print(\"Comparison (Test):\")\n",
    "for name, acc, tsec, params in summary:\n",
    "    # TODO 5: Print formatted comparison line\n",
    "    print(f\"- {name:10s} | test_acc={acc:.4f} | time={tsec:.1f}s | params={params:,}\")\n",
    "\n",
    "\n",
    "# -------- Plot Validation Accuracy Curves --------\n",
    "# TODO 6: Create figure\n",
    "plt.figure(figsize=(____, ____))\n",
    "\n",
    "# TODO 7: Plot AlexNet-like validation accuracy\n",
    "plt.plot(hist_alex.history.get(\"_______________\", []), label=\"________________________\")\n",
    "\n",
    "# TODO 8: Plot VGG-style validation accuracy\n",
    "plt.plot(hist_vgg.history.get(\"_______________\", []), label=\"________________________\")\n",
    "\n",
    "# TODO 9: Add x/y labels, legend, title\n",
    "plt.xlabel(\"__________\")\n",
    "plt.ylabel(\"_____________________\")\n",
    "plt.legend()\n",
    "plt.title(\"__________________________________________\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1e14e",
   "metadata": {},
   "source": [
    "## Q7 â€” Regularization Mini-Experiment (One Controlled Change)\n",
    "\n",
    "Choose one model and change **one thing**:\n",
    "- Dropout 0.5 -> 0.3 or 0.6 OR\n",
    "- Add small RandomCrop/Zoom (keep realistic)\n",
    "\n",
    "Retrain and compare best val acc vs baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea8163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q7 â€” Mini Experiment: Change Dropout (0.5 â†’ 0.3)\n",
    "# ============================================================\n",
    "# Controlled experiment:\n",
    "#   - Keep AlexNet-like architecture the same\n",
    "#   - Change ONLY the dropout rate from 0.5 to 0.3\n",
    "#\n",
    "# Complete the TODO sections to:\n",
    "#  1) Build a configurable AlexNet with dropout parameter \"drop\"\n",
    "#  2) Train the modified model\n",
    "#  3) Compare best validation accuracy vs the baseline AlexNet\n",
    "#  4) Store results in a dictionary\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "def build_alexnet_cifar_dropout(drop=0.5, input_shape=(32, 32, 3), num_classes=10):\n",
    "    # TODO 1: Define input layer\n",
    "    inputs = layers.__________(shape=__________________)\n",
    "\n",
    "    # -------- Block 1 --------\n",
    "    x = layers.Conv2D(_____, _____, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.________________()(x)          # BatchNorm\n",
    "    x = layers.__________________(_____)(x)   # MaxPool\n",
    "\n",
    "    # -------- Block 2 --------\n",
    "    x = layers.Conv2D(_____, _____, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.________________()(x)\n",
    "    x = layers.__________________(_____)(x)\n",
    "\n",
    "    # -------- Block 3 --------\n",
    "    x = layers.Conv2D(_____, _____, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(_____, _____, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.__________________(_____)(x)\n",
    "\n",
    "    # -------- Classifier --------\n",
    "    x = layers.__________()(x)                           # Flatten\n",
    "    x = layers.Dense(_____, activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 2: Use dropout rate given by parameter \"drop\"\n",
    "    x = layers.__________(_____)(x)\n",
    "\n",
    "    outputs = layers.Dense(_____, activation=\"_____\")(x)\n",
    "\n",
    "    # TODO 3: Return a Keras model with a name that includes the dropout value\n",
    "    return tf.keras.Model(inputs, outputs, name=f\"____________________________\")\n",
    "\n",
    "\n",
    "# TODO 4: Build the modified model with dropout = 0.3\n",
    "alex_drop03 = build_alexnet_cifar_dropout(\n",
    "    drop=____,\n",
    "    input_shape=____________________,\n",
    "    num_classes=____________________\n",
    ")\n",
    "\n",
    "# TODO 5: Compile the modified model (same settings as baseline)\n",
    "alex_drop03.compile(\n",
    "    optimizer=tf.keras.optimizers.__________(_____),\n",
    "    loss=\"_______________________________\",\n",
    "    metrics=[\"__________\"]\n",
    ")\n",
    "\n",
    "# TODO 6: Train and measure training time\n",
    "t0 = time.__________()\n",
    "hist_alex_drop03 = alex_drop03.fit(\n",
    "    __________,\n",
    "    validation_data=__________,\n",
    "    epochs=__________,\n",
    "    callbacks=______________________________\n",
    ")\n",
    "time_alex_drop03 = time.__________() - t0\n",
    "\n",
    "\n",
    "# -------- Compare Results --------\n",
    "# TODO 7: Compute best validation accuracy for baseline and modified models\n",
    "baseline_best_val = float(np.__________(hist_alex.history.get(\"_______________\", [np.nan])))\n",
    "modified_best_val = float(np.__________(hist_alex_drop03.history.get(\"_______________\", [np.nan])))\n",
    "\n",
    "# TODO 8: Store mini-experiment results in a dictionary\n",
    "mini_exp = {\n",
    "    \"baseline_alex_drop0.5\": {\n",
    "        \"best_val_acc\": ____________,\n",
    "        \"test_acc\": float(__________)\n",
    "    },\n",
    "    \"modified_alex_drop0.3\": {\n",
    "        \"best_val_acc\": ____________,\n",
    "        \"train_time_sec\": float(__________)\n",
    "    },\n",
    "}\n",
    "\n",
    "print(mini_exp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5f47a",
   "metadata": {},
   "source": [
    "## Q8 â€” Qualitative Error Analysis (Fast, Visual)\n",
    "\n",
    "Pick the best model and show 12 test images with:\n",
    "- true label\n",
    "- predicted label\n",
    "- confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bada76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Question Q8 â€” Select Best Model & Visualize Predictions\n",
    "# ============================================================\n",
    "# Complete the TODO sections to:\n",
    "#  1) Select the best model based on test accuracy\n",
    "#  2) Get a batch from the test dataset\n",
    "#  3) Run prediction and compute predicted labels + confidences\n",
    "#  4) Visualize 12 test images with True label, Pred label, and confidence\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO 1: Choose the best model based on test accuracy\n",
    "best_name, best_model = (\n",
    "    (\"______________\", _____________) if _____________ >= _____________\n",
    "    else (\"______________\", _____________)\n",
    ")\n",
    "\n",
    "print(\"Best model:\", best_name)\n",
    "\n",
    "# TODO 2: Get one batch from the test dataset\n",
    "x_batch, y_batch = next(iter(______________))\n",
    "\n",
    "# TODO 3: Predict class probabilities for this batch\n",
    "probs = best_model.__________(x_batch, verbose=____)\n",
    "\n",
    "# TODO 4: Convert probabilities to predicted class labels\n",
    "preds = np.__________(probs, axis=____)\n",
    "\n",
    "# TODO 5: Confidence = max probability per sample\n",
    "confs = np.__________(probs, axis=____)\n",
    "\n",
    "# -------- Visualization --------\n",
    "plt.figure(figsize=(____, ____))\n",
    "for i in range(____):\n",
    "    ax = plt.subplot(____, ____, i + 1)\n",
    "\n",
    "    # TODO 6: Show image i from the batch\n",
    "    plt.__________(x_batch[i])\n",
    "\n",
    "    # TODO 7: Get true and predicted class names\n",
    "    t = class_names[int(______________)]\n",
    "    p = class_names[int(______________)]\n",
    "\n",
    "    # TODO 8: Title format: True label, Pred label, confidence (2 decimals)\n",
    "    plt.title(f\"T:{t}\\nP:{p} ({confs[i]:.2f})\", fontsize=____)\n",
    "\n",
    "    # TODO 9: Hide axes\n",
    "    plt.axis(\"____\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3eb39e",
   "metadata": {},
   "source": [
    "# Short Discussion (Answer Each Question Clearly)\n",
    "\n",
    "- **Review and answer the following questions carefully briefly**\n",
    "\n",
    "1) Why must AlexNet be **adapted** for 32Ã—32 images (compared to ImageNet 224Ã—224)?  \n",
    "2) Which model is more efficient on CPU and why?  \n",
    "3) What did your mini-experiment change and what did you observe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971620c8-12f0-4745-8943-43591f78d7e8",
   "metadata": {},
   "source": [
    "### Q9. Why must AlexNet be adapted for 32Ã—32 images (compared to ImageNet 224Ã—224)? \n",
    "\n",
    "\n",
    "**Type your answer (here)....**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789641d2-fccf-49bd-9dac-841b3dab55c0",
   "metadata": {},
   "source": [
    "### Q10. Which model is more efficient on CPU and why? \n",
    "\n",
    "\n",
    "**Type your answer (here)....**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b25f9-bc62-44cd-ac39-c2059f7781c2",
   "metadata": {},
   "source": [
    "### Q11. What did your mini-experiment change and what did you observe? \n",
    "\n",
    "\n",
    "**Type your answer (here)....**\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe5f61a",
   "metadata": {},
   "source": [
    "### ðŸŽ‰ Congratulations!\n",
    "\n",
    "You have successfully completed **A3-AlexNet-VGG**. Excellent work exploring and comparing **convolutional neural network architectures**, specifically **AlexNet** and **VGG16**, and analyzing how **depth, parameterization, and architectural design choices** affect performance on the **CIFAR-10 dataset** under **CPU-only training constraints**.\n",
    "\n",
    "### **Submission Instructions**\n",
    "\n",
    "Please submit a **GitHub repository link** on Canvas that contains:\n",
    "- The **completed Jupyter notebook**\n",
    "- Any additional files required for the assignment (if applicable)\n",
    "\n",
    "Before submitting, ensure that:\n",
    "- All **code cells (Q1â€“Q8)** have been executed successfully\n",
    "- All **Markdown responses (Q9â€“Q11)** have been completed\n",
    "- The notebook is **saved after execution** so that outputs are visible\n",
    "\n",
    "Once verified, **push the final version to GitHub** and submit the repository link on Canvas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-ee5841",
   "language": "python",
   "name": "cs-ee5841"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
